{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.766490</td>\n",
       "      <td>0.881365</td>\n",
       "      <td>0.313023</td>\n",
       "      <td>0.763439</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>0.266815</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.475312</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561184</td>\n",
       "      <td>0.522992</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.391253</td>\n",
       "      <td>0.585122</td>\n",
       "      <td>0.394557</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978542</td>\n",
       "      <td>0.770067</td>\n",
       "      <td>0.840298</td>\n",
       "      <td>0.271796</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.262192</td>\n",
       "      <td>0.264875</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>0.505267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.480237</td>\n",
       "      <td>0.666938</td>\n",
       "      <td>0.336440</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.446013</td>\n",
       "      <td>0.416345</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.935217</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.868141</td>\n",
       "      <td>0.268766</td>\n",
       "      <td>0.762329</td>\n",
       "      <td>0.281122</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>0.513018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565477</td>\n",
       "      <td>0.546030</td>\n",
       "      <td>0.678939</td>\n",
       "      <td>0.289354</td>\n",
       "      <td>0.559515</td>\n",
       "      <td>0.402727</td>\n",
       "      <td>0.415489</td>\n",
       "      <td>0.311911</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941878</td>\n",
       "      <td>0.765304</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.765647</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.789434</td>\n",
       "      <td>0.414999</td>\n",
       "      <td>0.507585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559734</td>\n",
       "      <td>0.510277</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.223826</td>\n",
       "      <td>0.614245</td>\n",
       "      <td>0.389197</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.938617</td>\n",
       "      <td>0.776520</td>\n",
       "      <td>0.864251</td>\n",
       "      <td>0.269796</td>\n",
       "      <td>0.762975</td>\n",
       "      <td>0.263984</td>\n",
       "      <td>0.268968</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>0.524303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561327</td>\n",
       "      <td>0.547271</td>\n",
       "      <td>0.663392</td>\n",
       "      <td>0.401270</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>0.507497</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.935192  0.766490  0.881365  0.313023  0.763439  0.267669  0.266815   \n",
       "1  0.978542  0.770067  0.840298  0.271796  0.766120  0.262192  0.264875   \n",
       "2  0.935217  0.753118  0.868141  0.268766  0.762329  0.281122  0.270177   \n",
       "3  0.941878  0.765304  0.868484  0.213661  0.765647  0.275559  0.266803   \n",
       "4  0.938617  0.776520  0.864251  0.269796  0.762975  0.263984  0.268968   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0  0.786444  0.475312  0.510600  ...    0.561184  0.522992  0.663793   \n",
       "1  0.786298  0.453981  0.505267  ...    0.557840  0.480237  0.666938   \n",
       "2  0.788042  0.410603  0.513018  ...    0.565477  0.546030  0.678939   \n",
       "3  0.789434  0.414999  0.507585  ...    0.559734  0.510277  0.662607   \n",
       "4  0.782484  0.490950  0.524303  ...    0.561327  0.547271  0.663392   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  Class  \n",
       "0  0.391253  0.585122  0.394557  0.418976  0.312697  0.005824      0  \n",
       "1  0.336440  0.587290  0.446013  0.416345  0.313423  0.000105      0  \n",
       "2  0.289354  0.559515  0.402727  0.415489  0.311911  0.014739      0  \n",
       "3  0.223826  0.614245  0.389197  0.417669  0.314371  0.004807      0  \n",
       "4  0.401270  0.566343  0.507497  0.420561  0.317490  0.002724      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.loc[:,\"V1\":\"Amount\"]\n",
    "fraud_class = df[\"Class\"]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "index, cols = new_df.index, new_df.columns\n",
    "x_scaled = min_max_scaler.fit_transform(new_df)\n",
    "norm_df = pd.DataFrame(x_scaled, columns=cols)\n",
    "norm_df[\"Class\"] = fraud_class\n",
    "norm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier for the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     93838\n",
      "          1       0.87      0.59      0.70       149\n",
      "\n",
      "avg / total       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = norm_df.loc[:,\"V1\":\"Amount\"], norm_df[\"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "clf = RandomForestClassifier(max_depth=2, n_estimators=20)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93825    13]\n",
      " [   61    88]]\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraud transactions: 15252\n",
      "Number of legitimate transactions: 8813765\n",
      "Ration of fraud/legitimate transactions = 0.00173047500132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f67ecc86310>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAHgCAYAAADHQUsEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67ec9ccc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud = norm_df[norm_df[\"Class\"] == 1].size\n",
    "legit = norm_df[norm_df[\"Class\"] == 0].size\n",
    "\n",
    "print \"Number of fraud transactions: {}\".format(fraud)\n",
    "print \"Number of legitimate transactions: {}\".format(legit)\n",
    "print \"Ration of fraud/legitimate transactions = {}\".format(float(fraud)/float(legit))\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.countplot(data=norm_df, x=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: It's apparent that the dataset is highly imbalanced and this is the reason we get a quite high precision in our predictions while the recall is still not good enough. Let's try to see if this can be improved by oversampling the fraud (minor) class, or undersampling the legit (major) class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      4874\n",
      "          1       0.98      0.73      0.84       160\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "under_sampling_fraud = norm_df[norm_df[\"Class\"] == 1]\n",
    "under_size = under_sampling_fraud.size\n",
    "under_sampling_legit = norm_df[norm_df[\"Class\"] == 0].sample(under_size)\n",
    "\n",
    "df_under = pd.concat([under_sampling_legit, under_sampling_fraud])\n",
    "X_under, y_under = df_under.loc[:,\"V1\":\"V28\"], df_under[\"Class\"]\n",
    "\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = (\n",
    "    train_test_split(X_under, y_under, test_size=0.33, random_state=42))\n",
    "\n",
    "clf_under = RandomForestClassifier(max_depth=2, n_estimators=20)\n",
    "\n",
    "clf_under.fit(X_train_under, y_train_under)\n",
    "\n",
    "predictions_under = clf_under.predict(X_test_under)\n",
    "\n",
    "print classification_report(y_test_under, predictions_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ovesampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97     93595\n",
      "          1       1.00      0.85      0.91     32701\n",
      "\n",
      "avg / total       0.96      0.96      0.96    126296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "over_sampling_fraud = norm_df[norm_df[\"Class\"] == 1]\n",
    "over_sampling_legit = norm_df[norm_df[\"Class\"] == 0]\n",
    "\n",
    "df_fraud= pd.concat([over_sampling_fraud]*200)\n",
    "df_over = pd.concat([over_sampling_legit, df_fraud])\n",
    "X_over, y_over = df_over.loc[:, \"V1\":\"V28\"], df_over[\"Class\"]\n",
    "\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = (\n",
    "    train_test_split(X_over, y_over, test_size=0.33, random_state=42))\n",
    "\n",
    "clf_over = RandomForestClassifier(max_depth=2, n_estimators=20)\n",
    "\n",
    "clf_over.fit(X_train_over, y_train_over)\n",
    "\n",
    "predictions_over = clf_over.predict(X_test_over)\n",
    "\n",
    "print classification_report(y_test_over, predictions_over)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
